# === Core Prediction Parameters ===
seq_len: 96                    # Input sequence length
horizon: 24                    # Prediction horizon
label_len: 48                  # Label length for decoder
input_size: 1                  # Input feature dimension
c_out: 1                       # Output dimension

# === Model Architecture ===
d_model: 512                   # Model dimension
n_heads: 8                     # Number of attention heads
e_layers: 2                    # Number of encoder layers
d_layers: 1                    # Number of decoder layers
d_ff: 2048                     # Feedforward dimension
dropout: 0.1                   # Dropout rate
activation: "gelu"             # Activation function

# === Attention Parameters ===
factor: 5                      # Attention factor
output_attention: false        # Output attention weights

# === Training Parameters ===
batch_size: 32                 # Batch size
learning_rate: 0.001           # Learning rate
num_epochs: 100                # Number of epochs
patience: 10                   # Early stopping patience
loss_function: "huber"         # Loss function type

# === Data Processing ===
features: "S"                  # S for univariate, M for multivariate
target: "OT"                   # Target column name
normalize: 2                   # Normalization method
freq: "h"                      # Frequency string
embed: "timeF"                 # Embedding type

# === Advanced Model Options ===
use_layer_norm: true           # Use layer normalization
use_revin: true                # Use RevIN normalization
moving_avg: 25                 # Moving average window

# === STDM Specific Parameters ===
CI: true                       # Channel independence
distil: true                   # Use distillation

# === MoTSE Architecture Parameters ===
num_experts: 8                 # Number of experts
num_experts_per_tok: 2         # Experts per token
connection_type: "adaptive"    # Connection type: linear, attention, concat, adaptive
motse_hidden_size: 1024        # MoTSE hidden size
motse_num_layers: 6            # MoTSE number of layers
motse_num_heads: 16            # MoTSE attention heads
motse_intermediate_size: 4096  # MoTSE intermediate size
router_aux_loss_factor: 0.02   # Router auxiliary loss factor
apply_aux_loss: true           # Apply auxiliary loss

# === PaddleNLP Decoder Parameters ===
use_paddlenlp_decoder: true    # Use PaddleNLP decoder for feature decoding
decoder_hidden_size: 512       # Decoder hidden size
decoder_num_layers: 3          # Number of decoder layers
decoder_num_heads: 8           # Number of attention heads in decoder
decoder_dropout: 0.1           # Decoder dropout rate

# === Generation Parameters ===
max_position_embeddings: 2048  # Maximum position embeddings
rope_theta: 10000.0            # RoPE theta parameter
use_cache: true                # Use KV cache

# === Device and Performance ===
device: "auto"                 # Device selection (auto/cuda/cpu)
mixed_precision: true          # Use mixed precision training